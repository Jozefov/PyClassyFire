{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PyClassyFire Tutorial: Classifying Chemical Compounds Using the ClassyFire API\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the **PyClassyFire** tutorial! This guide will walk you through the process of classifying a large set of chemical compounds using the [ClassyFire](http://classyfire.wishartlab.com/) API. We'll utilize the `PyClassyFire` package, which provides a command-line interface (CLI) and programmatic access to the ClassyFire service, enabling efficient and scalable classification of chemical structures.\n",
    "\n",
    "By the end of this tutorial, you'll be able to:\n",
    "\n",
    "1. **Preprocess your SMILES data**: Prepare your unique SMILES strings for classification.\n",
    "2. **Submit classification jobs**: Use the `PyClassyFire` package to send your data to the ClassyFire API.\n",
    "3. **Retrieve and process results**: Collect the classification results and merge them with your original data.\n",
    "4. **Save the annotated data**: Store the enriched dataset for further analysis.\n",
    "\n",
    "Let's get started!\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before diving into the tutorial, ensure you have the following:\n",
    "\n",
    "- **Conda Environment**: A Conda environment named `classyfire_env` with all necessary dependencies installed.\n",
    "- **PyClassyFire Package**: Installed and accessible within your Conda environment.\n",
    "- **Unique SMILES Data**: A TSV file containing approximately 16,000 unique SMILES strings located at `/Users/macbook/CODE/PyClassyFire/data/unique_valid_smiles_no_header.tsv`.\n",
    "\n",
    "> **Note:** This tutorial assumes that the Conda environment and `PyClassyFire` package are already set up. If not, please refer to the [repository's README](https://github.com/yourusername/PyClassyFire) for setup instructions.\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [Importing Necessary Libraries](#importing-libraries)\n",
    "2. [Loading and Exploring the Data](#loading-data)\n",
    "3. [Preparing the SMILES Data for Classification](#preparing-data)\n",
    "4. [Submitting Classification Jobs to ClassyFire API](#submitting-jobs)\n",
    "5. [Monitoring Job Progress](#monitoring-progress)\n",
    "6. [Retrieving and Processing Results](#retrieving-results)\n",
    "7. [Saving the Annotated Data](#saving-data)\n",
    "8. [Conclusion](#conclusion)\n"
   ],
   "id": "82b5bab971f2733b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:17.446147Z",
     "start_time": "2025-01-01T23:10:17.062676Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "from fontTools.subset import intersect\n",
    "\n",
    "from classyfire_cli.src.utils import MoleCule, load_existing_results, save_intermediate_results\n",
    "from classyfire_cli.src.batch import process_batches_with_saving_and_retry"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:17.452674Z",
     "start_time": "2025-01-01T23:10:17.450474Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "smiles_file_path = '../data/unique_valid_smiles_no_header.tsv'\n",
    "output_dir = '../data/intermediate_results/'\n",
    "final_output_path = '/Users/macbook/CODE/PyClassyFire/data/classified_smiles.tsv'"
   ],
   "id": "6545871a47e06cba",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:19.403980Z",
     "start_time": "2025-01-01T23:10:17.484901Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load SMILES data\n",
    "smiles_df = pd.read_csv(smiles_file_path, sep='\\t', header=None, names=['SMILES']).dropna()\n",
    "\n",
    "# Canonicalize SMILES\n",
    "smiles_df['Canonical_SMILES'] = smiles_df['SMILES'].apply(\n",
    "    lambda x: MoleCule.from_smiles(x).canonical_smiles if x else None\n",
    ").dropna()"
   ],
   "id": "afbafdb7a69c2e6a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:19.418018Z",
     "start_time": "2025-01-01T23:10:19.414913Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Remove invalid entries\n",
    "invalid_smiles = smiles_df['Canonical_SMILES'].isnull().sum()\n",
    "print(f\"Number of invalid SMILES after canonicalization: {invalid_smiles}\")\n",
    "\n",
    "if invalid_smiles > 0:\n",
    "    smiles_df = smiles_df.dropna(subset=['Canonical_SMILES'])\n",
    "    print(f\"Removed {invalid_smiles} invalid SMILES entries.\")"
   ],
   "id": "54e7162949f396e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid SMILES after canonicalization: 0\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:19.444531Z",
     "start_time": "2025-01-01T23:10:19.440611Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Reset index after cleaning\n",
    "smiles_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Extract the list of canonical SMILES\n",
    "canonical_smiles_list = smiles_df['Canonical_SMILES'].tolist()\n",
    "canonical_smiles_list = list(set(canonical_smiles_list))"
   ],
   "id": "ddd2aeb08beeb1e3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:19.452295Z",
     "start_time": "2025-01-01T23:10:19.450522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define parameters\n",
    "batch_size = 100          # Number of SMILES per job\n",
    "save_interval = 20        # Save intermediate results every 20 batches\n",
    "output_dir = '/Users/macbook/CODE/PyClassyFire/data/intermediate_results/'\n",
    "max_retries = 3           # Maximum number of retries for failed batches\n",
    "retry_delay = 10         # Delay between retries in seconds (5 minutes)"
   ],
   "id": "2e2d3d4f8b60398a",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-01-01T23:29:20.700424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Process the batches with resumption and retry logic\n",
    "intermediate_files = process_batches_with_saving_and_retry(\n",
    "    smiles_list=canonical_smiles_list,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=output_dir,\n",
    "    max_retries=max_retries,\n",
    "    retry_delay=retry_delay\n",
    ")"
   ],
   "id": "1dc92d621e1c6491",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All  smiles: 13984\n",
      "Already processed SMILES: 493\n",
      "Remaining SMILES to process: 13503\n",
      "Remaining unique SMILES to process after removing duplicates: 13503\n",
      "Total remaining batches to process: 136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Batches:   0%|          | 0/136 [00:00<?, ?it/s]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted Batch 6 with Query ID 12021447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Batches:   1%|          | 1/136 [01:54<4:17:42, 114.54s/it]\u001B[A\u001B[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 6 completed with 100 molecules.\n",
      "Saved intermediate results to /Users/macbook/CODE/PyClassyFire/data/intermediate_results/intermediate_6.json\n",
      "Submitted Batch 7 with Query ID 12021449\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:10:12.638305Z",
     "start_time": "2025-01-01T22:50:02.485096Z"
    }
   },
   "cell_type": "code",
   "source": "len(set(canonical_smiles_list))",
   "id": "b0886000b2169998",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13685"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def merge_intermediate_results(intermediate_files):\n",
    "    \"\"\"\n",
    "    Merges multiple intermediate JSON result files into a single dictionary.\n",
    "    \"\"\"\n",
    "    merged_results = {}\n",
    "    for file in intermediate_files:\n",
    "        try:\n",
    "            with open(file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                merged_results.update(data)\n",
    "            print(f\"Successfully merged results from {file}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error merging results from {file}: {e}\")\n",
    "    return merged_results"
   ],
   "id": "dc9bdca23fccf99a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge all intermediate results\n",
    "merged_results = merge_intermediate_results(intermediate_files)"
   ],
   "id": "3e46aa4945742ec7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Display the number of classified SMILES\n",
    "classified_count = len(merged_results)\n",
    "print(f\"Total number of classified SMILES: {classified_count}\")\n",
    "\n",
    "# Convert the merged results dictionary to a DataFrame\n",
    "results_df = pd.DataFrame.from_dict(merged_results, orient='index')\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(columns={'index': 'Canonical_SMILES'}, inplace=True)\n",
    "\n",
    "# Merge the classification results with the original SMILES DataFrame\n",
    "annotated_df = pd.merge(smiles_df, results_df, on='Canonical_SMILES', how='left')"
   ],
   "id": "55114f2112ee54c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# Handle unclassified SMILES\n",
    "unclassified = annotated_df['superclass'].isnull().sum()\n",
    "print(f\"Number of SMILES without classification: {unclassified}\")\n",
    "\n",
    "# Fill NaN values with 'Unknown'\n",
    "annotated_df[['superclass', 'class', 'subclass']] = annotated_df[['superclass', 'class', 'subclass']].fillna('Unknown')\n",
    "\n",
    "# Save the annotated DataFrame to a TSV file\n",
    "annotated_df.to_csv(final_output_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Annotated data has been saved to {final_output_path}\")"
   ],
   "id": "67ae5471c400216d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "28e7469ee2118b8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "77ad7ac4166aaa1c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T20:51:33.375005Z",
     "start_time": "2025-01-01T20:51:33.371444Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def analyze_structure(data, level=0):\n",
    "    \"\"\"Recursively analyze and print the structure of JSON data.\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        print(\" \" * level + f\"Object with keys: {list(data.keys())}\")\n",
    "        for key, value in data.items():\n",
    "            analyze_structure(value, level + 2)\n",
    "    elif isinstance(data, list):\n",
    "        print(\" \" * level + f\"List of {len(data)} items\")\n",
    "        if len(data) > 0:\n",
    "            analyze_structure(data[0], level + 2)  # Analyze the first item as representative\n",
    "    else:\n",
    "        print(\" \" * level + f\"Value type: {type(data).__name__}\")\n",
    "\n"
   ],
   "id": "afdc3fa695ec8852",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T20:51:36.018760Z",
     "start_time": "2025-01-01T20:51:36.010196Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the JSON file\n",
    "file_path = \"/Users/macbook/CODE/PyClassyFire/data/intermediate_results/intermediate_1.json\"  # Replace with your file's path\n",
    "with open(file_path, \"r\") as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Analyze the JSON structure\n",
    "analyze_structure(json_data)"
   ],
   "id": "2550c36dbcfa512",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object with keys: ['12021409']\n",
      "  List of 100 items\n",
      "    Object with keys: ['identifier', 'smiles', 'inchikey', 'kingdom', 'superclass', 'class', 'subclass', 'intermediate_nodes', 'direct_parent', 'alternative_parents', 'molecular_framework', 'substituents', 'description', 'external_descriptors', 'ancestors', 'predicted_chebi_terms', 'predicted_lipidmaps_terms', 'classification_version']\n",
      "      Value type: str\n",
      "      Value type: str\n",
      "      Value type: str\n",
      "      Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "      Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "      Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "      Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "      List of 0 items\n",
      "      Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "        Value type: str\n",
      "      List of 27 items\n",
      "        Object with keys: ['name', 'description', 'chemont_id', 'url']\n",
      "          Value type: str\n",
      "          Value type: str\n",
      "          Value type: str\n",
      "          Value type: str\n",
      "      Value type: str\n",
      "      List of 43 items\n",
      "        Value type: str\n",
      "      Value type: str\n",
      "      List of 0 items\n",
      "      List of 51 items\n",
      "        Value type: str\n",
      "      List of 36 items\n",
      "        Value type: str\n",
      "      List of 1 items\n",
      "        Value type: str\n",
      "      Value type: str\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:17:25.411061Z",
     "start_time": "2025-01-01T23:17:25.395572Z"
    }
   },
   "cell_type": "code",
   "source": [
    "existing_smiles = load_existing_results(output_dir)\n",
    "print(f\"Already processed SMILES: {len(existing_smiles[0])}\")"
   ],
   "id": "b8b3148522350d69",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already processed SMILES: 300\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T22:59:38.448221Z",
     "start_time": "2025-01-01T22:59:38.442291Z"
    }
   },
   "cell_type": "code",
   "source": "existing_smiles",
   "id": "c1d582c0a0f1d31f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'C(C=CC1=CC=CC=C1)N1CCN(CC1)C(C1=CC=CC=C1)C1=CC=CC=C1',\n",
       "  'C(CN(CC1=CC=CC=N1)CC1=CC=CC=N1)N(CC1=CC=CC=N1)CC1=CC=CC=N1',\n",
       "  'C(N1C=CN=C1)C1=CC(CN2C=CN=C2)=CC(CN2C=CN=C2)=C1',\n",
       "  'C1=CC=C(C=C1)C1=C2C=CC3=C(C=CN=C3C2=NC=C1)C1=CC=CC=C1',\n",
       "  'C1CN(CCN1)C1=CC=C(C=C1)C1=CN2N=CC(=C2N=C1)C1=CC=NC2=CC=CC=C12',\n",
       "  'CC#CC1(O)CCC2C3CCC4=CC(=O)CCC4=C3C(CC12C)C1=CC=C(C=C1)N(C)C',\n",
       "  'CC(=O)NCC1CN(C(=O)O1)C1=CC(F)=C(C=C1)N1CCN(CC1)C(=O)CO',\n",
       "  'CC(C)(C)NC(=O)COC1=CC=C(CNC2=CC3=C(NC(=O)N3)C=C2)C=C1',\n",
       "  'CC(C)(C)SC1=C(CC(C)(C)C(O)=O)N(CC2=CC=C(Cl)C=C2)C2=C1C=C(OCC1=NC3=CC=CC=C3C=C1)C=C2',\n",
       "  'CC(C)(CC1CC2=CC=CC=C2C1)NCC(O)COC1=C(C=CC(CCC(O)=O)=C1)C#N',\n",
       "  'CC(C)(OCc1nn(Cc2ccccc2)c2ccccc12)C(O)=O',\n",
       "  'CC(C)C(=O)OCC1(CO1)C1=C(OC(=O)C(C)C)C=C(C)C=C1',\n",
       "  'CC(C)C1=NOC(=N1)C1CCN(CC1)C1=C(C(NC2=C(F)C=C(C=C2)S(C)(=O)=O)=NC=N1)[N+]([O-])=O',\n",
       "  'CC(C)CC(N1CC2=CC=CC=C2C1=O)C(=O)NC1=CC=CC2=C1C=CN2',\n",
       "  'CC(C)OC1=CC=C(C=C1)C1=CN2N=CC(=C2N=C1)C1=CC=NC2=CC=CC=C12',\n",
       "  'CC(C1CCC2C3CC=C4CC(CC(O)C4(C)C3CCC12C)OC1OC(COC2OC(CO)C(O)C(O)C2O)C(O)C(O)C1O)C1CC(CO)=C(C)C(=O)O1',\n",
       "  'CC(CCC1=CC=CC=C1)NC(C)C(O)C1=CC=C(O)C=C1',\n",
       "  'CC(CCC1C(=C)C(CC2C(C)(C)C(O)CCC12C)OC1OCC(O)C(O)C1O)=CCO',\n",
       "  'CC(CO)NC(=O)C1=NC(=NC(=C1)C1=CC=C(OC(F)(F)F)C=C1)C1=CN=CC=C1',\n",
       "  'CC(N(C)C(=O)OC(C)(C)C)C(=O)NC(C1CCCCC1)C(=O)N1CCCC1C1=NC(=CS1)C(=O)C1=CC(O)=CC=C1',\n",
       "  'CC(OCC1(CCC2(CCC(=O)N2)CN1)C1=CC=CC=C1)C1=CC(=CC(=C1)C(F)(F)F)C(F)(F)F',\n",
       "  'CC(Sc1nc2ccccc2[nH]1)C(=O)NN=Cc1cc(Br)ccc1O',\n",
       "  'CC1(C)CC(CC(C)(C)N1)NC(=O)C(=O)NC1=CC=C(Br)C=C1',\n",
       "  'CC1(C)CC(CC(C)(C)N1)NC(=O)C(=O)NC1=CC=C(Cl)C=C1',\n",
       "  'CC1(C)CC(NC2=C1C=C(C=C2)C(=O)NS(=O)(=O)C1CC1)C1=CC(=CC=C1)N1CCOCC1',\n",
       "  'CC1(O)CCC2C(OC(=O)C2=C)C2C1CC(OC1OC(CO)C(O)C(O)C1O)C2=C',\n",
       "  'CC12CC3(O)OC(O1)C1(COC(=O)C4=CC=CC=C4)C3CC21OC1OC(COC(=O)C2=CC=CC=C2)C(O)C(O)C1O',\n",
       "  'CC1=C(C)C(NC2=NC(=NC(=N2)N2CCOCC2)N2CCOCC2)=CC=C1',\n",
       "  'CC1=C(C=C(NC(=O)C2=CC(=NC=C2)C(F)(F)F)C=C1)C1=CC(=NC(OCCO)=C1)N1CCOCC1',\n",
       "  'CC1=C(CC(O)=O)C2=C(C=CC(F)=C2)C1=CC1=CC=C(C=C1)S(C)=O',\n",
       "  'CC1=C(CCC(=O)NC(CCCNC(N)=O)C(O)=O)C(=O)OC2=C1C=CC(O)=C2',\n",
       "  'CC1=C2C=C(C=CC2=NN1)C1=CC(OCC(N)CC2=CNC3=CC=CC=C23)=CN=C1',\n",
       "  'CC1=CC(=NN=C1C(=O)N1CCN(CC1)C1=NC=CC=N1)C1=CC=CC=C1',\n",
       "  'CC1=CC2=C(C=C1)N=C(NC(=O)CC1=CC3=C(OCC3)C=C1)S2',\n",
       "  'CC1=CC=C(S1)C=NNC(=O)C1=CC=C(O1)C(=O)NN=CC1=CC=C(C)S1',\n",
       "  'CC1=CC=CC(=N1)C1=NN2CCCC2=C1C1=C2C=C(C=CC2=NC=C1)C(N)=O',\n",
       "  'CC1=CC=CC=C1NC1=NC=CC(=N1)C1CCCN(C1)C(=O)C1CCC1',\n",
       "  'CC1=NC(=CS1)C1=NC2=C(CN(CC2)C(=O)COC2=CC=C(Cl)C=C2)S1',\n",
       "  'CC1=NN(C(=O)C2=CN=CC=C2)C(C)=C1SC1=CC=C(Br)C=C1',\n",
       "  'CC1C(C)C(=O)OC2C(O)C(OC(C)=O)C3(COC(C)=O)C(OC(C)=O)C(=O)C4C(OC(C)=O)C3(OC4(C)COC(=O)C3=C1N=CC=C3)C2(C)O',\n",
       "  'CC1C2C(CC3=CNC4=CC=CC=C34)NC(=O)C22C(C=CCC(C)C=C(C)C(O)C(=O)C=CC2=O)C2OC12C',\n",
       "  'CC1C2C(CC3C4CCC5CC(CCC5(C)C4CCC23C)OC2OC(CO)C(O)C(O)C2OC2OC(CO)C(O)C(O)C2O)OC11CCC(C)CO1',\n",
       "  'CC1C2OC(=O)C1C1(C)C(C2O)C2(C)C(O)C(=O)C=C(C)C2CC1=O',\n",
       "  'CC1CC(N)CC(C1)C1=C(NC(=O)C2=NC(=C(F)C=C2)C2=C(F)C=CC=C2F)C=NC=C1',\n",
       "  'CC1CC(NC2=CC=C(Cl)C=C2)C2=C(C=CC(=C2)C2=CC=C(C=C2)C(=O)NCCOCCOCCOCC(=O)NC(C(=O)N2CC(O)CC2C(=O)NCC2=CC=C(C=C2)C2=C(C)N=CS2)C(C)(C)C)N1C(C)=O',\n",
       "  'CC1CC2=CC=CC=C2N1S(=O)(=O)C1=C(C)SC(=C1)C1=NC(C)=CS1',\n",
       "  'CC1CCCN(CCCNC(=O)C2=CC(CN3C4=CC=CC=C4C(=O)N4CCCC4C3=O)=CC=C2)C1',\n",
       "  'CC1CN(CC(C)N1)C1=NC=C(C(C)=C1)C1=CC=C(C=C1)C1=NC2=C(C=CN2C)C(=O)N1',\n",
       "  'CC1NC2N(C1=O)C1=CC=CC=C1C21CC2N3C(=O)C4=CC=CC=C4N=C3C(O1)N(C)C2=O',\n",
       "  'CC1OC(OC2C(OC(=O)C34CCC(C)(C)CC3C3=CCC5C6(C)CCC(OC7OC(C(O)C(O)C7OC7OC(CO)C(O)C(O)C7O)C(O)=O)C(C)(C=O)C6CCC5(C)C3(C)CC4O)OC(C)C(OC(C)=O)C2OC2OC(CO)C(O)C2O)C(O)C(O)C1OC1OCC(O)C(O)C1O',\n",
       "  'CC1OC(OC2C3OC3(CO)C3C2C=COC3OC2OC(CO)C(O)C(O)C2O)C(OC(C)=O)C(OC(=O)C=CC2=CC=CC=C2)C1OC(=O)C=CC1=CC=CC=C1',\n",
       "  'CC1OC(OC2COC(OC3CCC4(C)C(CCC5(C)C4CC=C4C6CC(C)(C)CCC6(CCC54C)C(=O)OC4OC(CO)C(O)C(O)C4O)C3(C)CO)C(O)C2OC2OC(CO)C(O)C(O)C2O)C(O)C(O)C1O',\n",
       "  'CCC(=C(C1=CC=C(O)C=C1)C1=CC=C(OCCNC)C=C1)C1=CC=CC=C1',\n",
       "  'CCC(=C(C1=CC=CC=C1)C1=CC=C(OCCNC)C=C1)C1=CC=CC=C1',\n",
       "  'CCC(C)C(N(C)C(=O)OCC1C2=CC=CC=C2C2=CC=CC=C12)C(O)=O',\n",
       "  'CCC(C)C1N(C(C(=O)N2CCOCC2)C2=COC(C)=N2)C(=O)C(NC1=O)C1CC2=CC=CC=C2C1',\n",
       "  'CCC(C)C=C(C)C=CC1=CC2=CC(=O)C(C)(O)C(OC(C)=O)C2CO1',\n",
       "  'CCC(C)NC(=O)CN1N=CC2=C(N(C)C(=O)CS2)C1=O',\n",
       "  'CCC(C1=CC=CC=C1)C1=C(O)C2=C(OC1=O)C=CC=C2',\n",
       "  'CCC(CC)NC(=O)CCC1CCN(CC1)C1=CC(NC2CC2)=NC=N1',\n",
       "  'CCC1=C2NC(C=C3NC(=CC4=NC(C(CCC(O)=O)C4C)=C(CC(=O)NC(CC(O)=O)C(O)=O)C4=NC(=C2)C(C)=C4C(O)=O)C(C)=C3C=C)=C1C',\n",
       "  'CCCCC(C)(CO)NC1=NC(N)=NC2=C1N=CC(F)=C2',\n",
       "  'CCCCCCC(=O)OC1(CCC2C3CCC4=CC(=O)CCC4C3CCC12C)C#C',\n",
       "  'CCCCCCCCCCCCCCCCOCC(COP(O)(=O)OCC[N+](C)(C)C)OC(C)=O',\n",
       "  'CCCCCCCCCCCCOC1OC(CO)C(OC2OC(CO)C(O)C(O)C2O)C(O)C1O',\n",
       "  'CCCS(=O)(=O)N1CCN(CC1)C1=NN=CC(=C1)N(C)C',\n",
       "  'CCN(CC)CCNC(=O)C1=CC=C(N)C=C1',\n",
       "  'CCN1C(CSC2=NC(C)=CC(C)=N2)=NC2=C1C=CC(NC(=O)C1=CN=CC=C1)=C2',\n",
       "  'CCN1C=CN=C1N1CCN(CC(=O)NCCOC)CC1',\n",
       "  'CCN=C1NC(NC(C)(C)C)=NC(Cl)=N1',\n",
       "  'CCNC(=O)C1=CC2=C(N=C(N)N=C2S1)C1=CC(OCCN2CCCC2)=C(Cl)C=C1Cl',\n",
       "  'CCOC(=O)C1=CC(NC(=O)CSC2=NN=C(C)N2CC2CCCO2)=CC=C1',\n",
       "  'CCOC(=O)C1=CC(NS(=O)(=O)C2=C(C)C=CC(=C2)C2=NNC(C)=C2)=CC=C1',\n",
       "  'CCOC(=O)CC1=NC2=C(N1)C=C(C=C2)N1CCN(C)CC1',\n",
       "  'CCOC1=C(C#N)C(N)=CC(NC(=O)CC2=C(OC)C=CC(OC)=C2)=N1',\n",
       "  'CCOC1=C2CN(C(=O)C2=C(OCC)C2=CC=CC=C12)C1=CC(F)=C(CC(O)=O)C=C1',\n",
       "  'CCOC1=CC=C(C=C1)C(=O)N1CCC2(CC1)NC(=O)C1=C(N2)C(Cl)=CC=C1',\n",
       "  'CCOC1=CC=C(NC(=O)C(CC2=CC=CC=C2)NC(=O)C2=NC(SCC)=NC=C2Cl)C=C1',\n",
       "  'CCOC1=CC=C(NC2=NC(=NC(NC3=CC=C(OCC)C=C3)=N2)N2CCOCC2)C=C1',\n",
       "  'CCOC1=NC2=CC=CC(C(=O)OCC3=C(C)OC(=O)O3)=C2N1CC1=CC=C(C=C1)C1=CC=CC=C1C1=NC(=O)ON1',\n",
       "  'CCOC1=NOC2=C1C=CC(OCCC1CCN(CC1)C1=NN=C(C)C=C1)=C2',\n",
       "  'CCn1cc(N2CCCC(C2)NC(=O)OC(C)(C)C)c(=O)n(CC)c1=O',\n",
       "  'CN(C)CCC(C1=CC=C(Br)C=C1)C1=CC=CC=N1',\n",
       "  'CN(C)CCNS(=O)(=O)CC1=CC(NC2=NC=CC(OC3=CC4=C(NC(C)=C4)C=C3)=N2)=CC=C1',\n",
       "  'CN(C)c1ccnc(n1)N1CCN(CC1)c1ncc(Br)cc1C(F)(F)F',\n",
       "  'CN(C1CCCCC1)C(=O)CCCOC1=CC2=C(NC(=O)C=C2)C=C1',\n",
       "  'CN(C1CCS(=O)(=O)C1)C(=O)c1ccc(COc2cccc(C)c2)o1',\n",
       "  'CN(C1CN(C1)c1nccnc1C#N)c1ncnc2ccsc12',\n",
       "  'CN(CC1=C(C)C2=CC=CC=C2O1)C(=O)C=CC1=CC2=C(NC(=O)CC2)N=C1',\n",
       "  'CN(CC1=CC(=CC=C1)C(F)(F)F)C(=O)C1=C(C)N=C2C=C(C)C=CN12',\n",
       "  'CN(CCc1noc(n1)-c1cc2cc(C)ccc2[nH]1)C(=O)c1cncc(Br)c1',\n",
       "  'CN1C(=O)C(O)=C(N=C1N1CCCCS1(=O)=O)C(=O)NCc1ccc(F)cc1',\n",
       "  'CN1C=C(C2=C1N=CN=C2N)C1=CC2=C(C=C1)N(CC2)C(=O)CC1=CC(=CC=C1)C(F)(F)F',\n",
       "  'CN1C=C(C2=CC=CC=C2C1=O)C1=C(OCC2CC2)C=CC(=C1)S(C)(=O)=O',\n",
       "  'CN1C=CC=C1C1=NNC(=C1)C(=O)NN=C(C)C1=CC=NC=C1',\n",
       "  'CN1C=NC(=C1C[N+](C)(C)CC=CC(=O)NC1=NC=C2N=CN=C(NC3=CC(Br)=C(Cl)C=C3)C2=C1)[N+]([O-])=O',\n",
       "  'CN1C=NC(CC(N)C(O)=O)=C1',\n",
       "  'CN1CCC2=CC(Cl)=C(O)C=C2C(C1)C1=CC=CC=C1',\n",
       "  'CN1CCN(CC1)C(=O)C1=CC=C(C=C1)N1N=C(C=C1C1=CC(=CC(=C1)C(C)(C)C)C(C)(C)C)C1=CC=C(C=C1)C(O)=O',\n",
       "  'CN1CCN(CC1)C1=NC(C)=NC2=C1N=C(N2C1CCOCC1)C1=CC=CC=C1Cl',\n",
       "  'CN1CCN(CC1)NC(=O)C1=CC(=NC2=CC=CC=C12)C1=CC=C(Cl)S1',\n",
       "  'CN1N=CC2=C(NC3=CC(C)=C(C)C=C3)N=C(N=C12)N1CCN(CCO)CC1',\n",
       "  'COC(=O)C(CC1=CC=CC=C1)NC(=O)C1=C(N=NS1)C1=CC=C(OC)C=C1',\n",
       "  'COC(=O)C(CC1=CC=CC=C1)NC(=O)CCC1NC(=O)C2=CC=CC=C2NC1=O',\n",
       "  'COC(=O)C1=CC(CN2C=NS(=O)(=O)C3=C2C=C(C)C=C3)=C(OC)C=C1',\n",
       "  'COC(=O)C1=COC(OC2OC(CO)C(O)C(O)C2O)C2C(CO)=CCC12O',\n",
       "  'COC(=O)C1=COC(OC2OC(CO)C(O)C(O)C2O)C2C1C(O)CC2(C)O',\n",
       "  'COC(=O)C1CCCN1C(=O)C1=CC(Cl)=C(OC2CCOCC2)N=C1',\n",
       "  'COC(=O)CCC(=O)CCCCCC(C)C(C)O',\n",
       "  'COC(CN1C=C(C(O)=O)C(=O)C(OC)=C1C(=O)OC)OC',\n",
       "  'COC1=C(C)C(OC(=O)C2=C(C)C(C)=C(O)C(C)=C2OC)=C(C)C(C)=C1C(O)=O',\n",
       "  'COC1=C(CSCC2=CC=CO2)C=C(C=NNS(=O)(=O)C2=CC=C(Br)C=C2)C=C1',\n",
       "  'COC1=C(Cl)C=C2C(=O)C(=C(C)NC2=C1)C1=CC=C(OC2=CC=C(OC(F)(F)F)C=C2)C=C1',\n",
       "  'COC1=C(NC2=NC=C(Cl)C(NC3C4CC(C=C4)C3C(N)=O)=N2)C=CC2=C1CCC(CC2)N1CCOCC1',\n",
       "  'COC1=C(O)C(C)=C(C(=O)OC2CC3=C(COC(C=CC)=C3)C(=O)C2(C)O)C(O)=C1',\n",
       "  'COC1=C(O)C=C(C=C1)C1=C(OC)C(=O)C2=C(O)C(OC)=C(OC)C=C2O1',\n",
       "  'COC1=C(O)C=C2OC(=C(OC)C(=O)C2=C1O)C1=CC(O)=C(O)C=C1',\n",
       "  'COC1=C(O)C=C2OC=C(C(=O)C2=C1O)C1=CC=C(O)C=C1',\n",
       "  'COC1=C(OC)C=C(C=C1)C1OC(C(C)C1C)C1=CC(OC)=C(OC)C=C1',\n",
       "  'COC1=C(OC)C=C2C3CC(OC(=O)C(N)C(C)C)C(CC(C)C)CN3CCC2=C1',\n",
       "  'COC1=C(OC2=NC=NC3=C2C=NN3C2=C(C)C=CC(Cl)=C2)C=CC(=C1)C(C)=O',\n",
       "  'COC1=C(OCCN2CCCC2)C=CC(=C1)N1C=NC2=C(SC(=C2)C2=CC=C(Cl)C=C2)C1=O',\n",
       "  'COC1=C2C(=O)C(=COC2=CC(O)=C1)C1=CC=C(O)C=C1',\n",
       "  'COC1=C2C(=O)C3=C(O)C=C(O)C=C3C(=O)C2=CC(CO)=C1',\n",
       "  'COC1=C2C=CC(=[O+]C2=CC(O)=C1C)C1=CC=CC=C1',\n",
       "  'COC1=CC(=CC(OC)=C1OC)C(=O)N(CCC1CCCN1C)CC(C)=CC1=CC=CC=C1F',\n",
       "  'COC1=CC(=O)OC(C=CC=CC=CC=CC2(C)OC(C)C(C)(O)C2O)=C1C',\n",
       "  'COC1=CC(C(=O)NC2=NC=C(Cl)C=C2)=C(NC(=O)C2=CC=C(C=C2)C(=N)N(C)C)C=C1',\n",
       "  'COC1=CC(C=CC(=O)N2CCC=CC2=O)=CC(OC)=C1OC',\n",
       "  'COC1=CC(O)=C2C(=O)C3=C(OC2=C1)C=C(O)C=C3C',\n",
       "  'COC1=CC2=C(C=C(N2)C(=O)NC(CC2=CC=CC=C2)C(=O)NCC2=CC=CO2)C=C1',\n",
       "  'COC1=CC=C(C=C1)C(=C1C(=O)NC2=CC=CC=C12)C1=CC=C(OC)C=C1',\n",
       "  'COC1=CC=C(C=C1)C(=O)NC(CC1=CC=CC=C1)C(O)=O',\n",
       "  'COC1=CC=C(NC2=NC3=NC=CN=C3C(NCC3=CC=CC=C3)=N2)C=C1',\n",
       "  'COC1=CC=CC2=C3C4=C(OCO4)C=C(C(O)=O)C3=C(C=C12)N(=O)=O',\n",
       "  'COC1=CC=CC=C1C1=CC(=O)C2=CC=CC=C2O1',\n",
       "  'COC1=NC(NC2=C(NC(C3=C4OC(F)(F)OC4=CC=C3)C3=C(Cl)C=CC=N3)C=CC(=C2)S(C)(=O)=O)=NC(=N1)N1CCNCC1',\n",
       "  'COC1=NC=NC(CN2C=C(C(=O)NCCO)C3=C2C=C(C)C=N3)=C1C',\n",
       "  'COC1=NN(C)C=C1C(=O)NC1=NC(=CS1)C1=CC(OC)=CC=C1',\n",
       "  'COC1=NN=C(C=C1)C(O)C1=C(Cl)C=C(F)C(=C1)C1=NC=NC2=C1C=CC(=C2)N1CCOCC1',\n",
       "  'COC1=[N+](N=CC(N)=C1)C1=CC=CC=C1',\n",
       "  'COC1C(O)C(OC2CCC3(C)C(CCC4C3CCC3(C)C(CCC43O)C3=CC(=O)OC3)C2)OC(C)C1OC1OC(COC2OC(CO)C(O)C(O)C2O)C(O)C(O)C1O',\n",
       "  'COC1CC(OC2CCC3(C)C(CCC4C3C(O)C(O)C3(C)C(CCC43O)C(C)OC(=O)C(C)=CC)C2)OC(C)C1OC1CC(OC)C(OC2CC(OC)C(OC3OC(C)C(OC4OC(CO)C(O)C(O)C4O)C(OC)C3O)C(C)O2)C(C)O1',\n",
       "  'COCCCNC1=NC(=NC2=C1C=NN2C)N1CCN(CC2=CC=CC=C2)CC1',\n",
       "  'COc1cccc2ccn(CCC(=O)NCCc3cn(C)c4ccccc34)c12',\n",
       "  'COc1ccccc1NC(=O)c1ccc(cc1)C(=O)Nc1ccccc1OC',\n",
       "  'CSCCC(NC(=O)C(Cc1ccccc1)NC(=O)CNC(=O)CNC(=O)C(N)Cc1ccc(O)cc1)C(O)=O',\n",
       "  'C[N+]1=C(\\\\C=N\\\\O)C=CC=C1',\n",
       "  'Cc1cc(NC(=O)COC(=O)c2cccc(NC(=O)C(F)(F)F)c2)no1',\n",
       "  'Cc1ccc(CNC(=O)CCC2=NNC3C4CC(NN4C=CN23)c2ccc(C)c(C)c2)o1',\n",
       "  'Cc1cnc(OC2CCN(CC2)S(=O)(=O)c2c(C)cc(C)cc2C)nc1',\n",
       "  'ClC1=C(Cl)C=C2N=C(NS(=O)(=O)C3=CC=CC=C3)NC2=C1',\n",
       "  'ClC1=CC=C(C=C1)C1(CCNCC1)C1=CC=C(C=C1)C1=CNN=C1',\n",
       "  'ClC1=CC=CC(CSC2=NN=C3C=CC(=NN23)C2=CC=CO2)=C1',\n",
       "  'ClC1=CN=C(NS(=O)(=O)C2=CC(=CS2)C2=NOC(=N2)C2CCCC2)C=C1',\n",
       "  'Cn1cnc2c(NCC(O)c3ccc4OCCc4c3)ncnc12',\n",
       "  'FC(F)(F)C1=CC=C(C=C1)N1N=NC(=N1)C(=O)NC1CCCC1',\n",
       "  'FC1=CN=C(C=C1)C1=NC=NC(=C1)C1=CC(Cl)=CC(=C1)C#N',\n",
       "  'FCC(=O)CNC(=O)C(CC1=CC=CC=C1)NC(=O)C1=CC=CC2=CC=CC=C12',\n",
       "  'IC1=CC=C(O1)C=NN1C(=O)C2C3C=CC(C2C1=O)C31CC1',\n",
       "  'N#CC1=C(NCC(N2CCOCC2)C2=CC=CC=C2)OC(CC2=CC=CC3=CC=CC=C23)=N1',\n",
       "  'NC(=N)NN=CC1=C(Cl)C=CC=C1Cl',\n",
       "  'NC(=O)NCCCC(NC(=O)CC1=CSC(=N1)C1=CC=CC=C1)C(O)=O',\n",
       "  'NC(=S)NN1C(CCC(O)=O)=CC=C1C1=CC=C(Br)C=C1',\n",
       "  'NC1=NC(=O)N(CC(CO)OCP(O)(O)=O)C=C1',\n",
       "  'NS(=O)(=O)C1=C(Cl)C=C2NC(CSCC3=CC=CC=C3)=NS(=O)(=O)C2=C1',\n",
       "  'O=C(CNC(=O)c1ccccc1)NC1CCN(CC1)c1nc2cccnc2s1',\n",
       "  'O=C(NC1=CC=CC2=C1N=CC=C2)C1=CC=C(C=C1)N1C(=O)C2C3CC(C=C3)C2C1=O',\n",
       "  'O=C(NC1=NC=CS1)C(CC1=CC=CC=C1)NC(=O)C1COC2=CC=CC=C2O1',\n",
       "  'O=C(NC1CCOCC1)C1=CC=C(C=C1)C1=NC=CC(=C1)C1=C(NN=C1)C1=CC=CC=N1',\n",
       "  'O=C(NCC1CCCCC1)C1=CC2=C(C=C1)N=CN=C2N1CCCC1',\n",
       "  'O=C(NCCC1=CCCCC1)C1=CC(=CC=C1)C(=O)NCCC1=CCCCC1',\n",
       "  'O=C1C2C(C3C(=O)CC2C2=CC=CC=C32)C(=O)N1C1=CN=CC=C1',\n",
       "  'O=C1NC2=C(C3=C(C=C2)N=CS3)C1=CC1=CN=CN1',\n",
       "  'O=S(=O)(C1CS(=O)(=O)CC1NCCC1=CNC2=CC=CC=C12)C1=CC=CC=C1',\n",
       "  'OC(=O)C(CC1=CC=C(O)C=C1)NC(=O)C=CC1=CC=C(O)C=C1',\n",
       "  'OC(=O)C(CC1=CC=CC=C1)N=C(O)CCN1C=CC2=C(Br)C=CC=C12',\n",
       "  'OC(=O)C(CC1=CC=CC=C1)NC(=O)C1=CC=C(F)C=C1',\n",
       "  'OC(=O)C(CC1=CNC2=C1C=C(O)C=C2)NC(=O)COC1=CC2=C(C=C1)C(=CC(=O)O2)C1=CC=CC=C1',\n",
       "  'OC(=O)C1=C(O)C=CC(NCC2=C(F)C(F)=C(C(F)=C2F)C(F)(F)F)=C1',\n",
       "  'OC(=O)C1=CC2=C(C=C1)N=C(S2)C1=CC=CC=C1Br',\n",
       "  'OC(=O)CC1=CC=C(CC2=CC(=NC(=C2)C(F)(F)F)C2=CC(Cl)=CC=C2)C=C1',\n",
       "  'OC(CC1=CSC(=N1)C1=CC(Br)=CC=C1)=NC(CC1=CNC2=CC=CC=C12)C(O)=O',\n",
       "  'OC(CN1CCN(CC1)C1=CC(Cl)=CC=C1)C(C1=CC=CC=C1)C1=CC=CC=C1',\n",
       "  'OC1=C(Br)C=C(Br)C2=C1N=CC=C2',\n",
       "  'OC1=CC(Cl)=C(I)C=C1NCC(=O)N1CCN(CC1)C(=O)C=C',\n",
       "  'OC1=CC2=C(C=C1)C(=O)N(C2)C1CCC(=O)NC1=O',\n",
       "  'OC1=CC=C(CCNC(=O)C=CC2=CC=C(O)C=C2)C=C1',\n",
       "  'OC1C(O)C(OC2=CC(O)=C3C(=O)C=C(OC3=C2)C2=CC=CC=C2)OC(C1O)C(O)=O',\n",
       "  'OCC(CC1=CC=CC=C1)NC1(CCCC1)C(O)=O',\n",
       "  'OCC1(O)COC(OCC2OC(OC3=CC4=C(C=CC(=O)O4)C=C3)C(O)C(O)C2O)C1O',\n",
       "  'OCC1OC(C(O)C(O)C1O)C1=C(O)C=CC(C(=O)C(O)CC2=CC=C(O)C=C2)=C1O',\n",
       "  'OCC1OC(C(O)C1O)N1C=NC2=C1N=CN=C2NCC1=CC=CO1',\n",
       "  'OCC1OC(OC2C(O)C(O)C(OC3=C(OC4=CC(O)=CC(O)=C4C3=O)C3=CC(O)=C(O)C=C3)OC2CO)C(O)C(O)C1O',\n",
       "  'OCCN1CC2(CCN(CC2)C2=NC3=C(CCCC3)C(=O)N2)c2c1cc(F)cc2F',\n",
       "  '[H]C(CC1=CC=CC=C1)(N=C(O)C1([H])CCC([H])(CC1)C(C)C)C(=O)N1CCC(CC1)C(O)=N',\n",
       "  '[H]C1(C)OC([H])(OCC2([H])OC([H])(OCC3(C)OC4=CC5=C(C(O)=C4C=C3)C(=O)C(=CO5)C3=CC=C(O)C=C3)C([H])(O)C([H])(O)C2([H])O)C([H])(O)C([H])(O)C1([H])O',\n",
       "  '[H]C1(CO)OC([H])(OC2=C(C=CC(O)=C2)C2=COC3=CC(OC)=CC(O)=C3C2=O)C([H])(O)C([H])(O)C1([H])O',\n",
       "  '[H]C12CC3([H])C4([H])CC=C5CC([H])(O)CC([H])(O)C5(C)C4([H])C([H])(O)CC3(C)C1([H])C(C)=C(CCC(=C)COC1([H])OC([H])(CO)C([H])(O)C([H])(O)C1([H])O)O2',\n",
       "  '[H]OC([H])([H])C1([H])OC([H])(OC2([H])OC([H])(C([H])([H])OC(=O)C([H])(C([H])([H])[H])C([H])([H])C([H])([H])[H])C([H])(O[H])C([H])(O[H])C2([H])O[H])C([H])(O[H])C([H])(O[H])C1([H])O[H]'},\n",
       " 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:17:28.102690Z",
     "start_time": "2025-01-01T23:17:28.097592Z"
    }
   },
   "cell_type": "code",
   "source": "a = set(canonical_smiles_list) - set(existing_smiles[0])",
   "id": "1b6db6fdd1d01d5",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:17:29.162579Z",
     "start_time": "2025-01-01T23:17:29.158148Z"
    }
   },
   "cell_type": "code",
   "source": "len(a)",
   "id": "986b4178f91894df",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13971"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:18:11.500859Z",
     "start_time": "2025-01-01T23:18:11.455424Z"
    }
   },
   "cell_type": "code",
   "source": [
    "b = set()\n",
    "for smi in existing_smiles[0]:\n",
    "    tmp = MoleCule.from_smiles(smi).canonical_smiles\n",
    "    b.add(tmp)"
   ],
   "id": "4a7dcb9e4433bb38",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:18:13.613544Z",
     "start_time": "2025-01-01T23:18:13.610202Z"
    }
   },
   "cell_type": "code",
   "source": "c = set(canonical_smiles_list) - b",
   "id": "24f29964490bb417",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:18:15.090319Z",
     "start_time": "2025-01-01T23:18:15.087323Z"
    }
   },
   "cell_type": "code",
   "source": "len(c)",
   "id": "d74a10851441a072",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13691"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:18:34.322589Z",
     "start_time": "2025-01-01T23:18:34.318953Z"
    }
   },
   "cell_type": "code",
   "source": "len(set(canonical_smiles_list))",
   "id": "fb00bdf1cc0bdff",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13984"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:19:35.285535Z",
     "start_time": "2025-01-01T23:19:35.282729Z"
    }
   },
   "cell_type": "code",
   "source": "len(b)",
   "id": "43d47fbfbc1f80d8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:21:22.975530Z",
     "start_time": "2025-01-01T23:21:22.972696Z"
    }
   },
   "cell_type": "code",
   "source": "b & c",
   "id": "6ed6318502f16829",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:23:33.973215Z",
     "start_time": "2025-01-01T23:23:33.970218Z"
    }
   },
   "cell_type": "code",
   "source": "weird = c - set(canonical_smiles_list) ",
   "id": "b0f83932822d9b55",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T23:23:36.891314Z",
     "start_time": "2025-01-01T23:23:36.888541Z"
    }
   },
   "cell_type": "code",
   "source": "weird",
   "id": "7584d909dae93c39",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4fa9e65396e46a6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:45:55.183266Z",
     "start_time": "2025-01-01T16:45:55.175544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_batches_with_saving_and_retry(\n",
    "    smiles_list,\n",
    "    batch_size=100,\n",
    "    save_interval=20,\n",
    "    output_dir='../data/intermediate_results/',\n",
    "    max_retries=3,\n",
    "    retry_delay=300  # in seconds (5 minutes)\n",
    "):\n",
    "    \"\"\"\n",
    "    Processes SMILES in batches, submits them to the ClassyFire API, saves intermediate results,\n",
    "    and implements retry logic for failed batches.\n",
    "    \n",
    "    Parameters:\n",
    "    - smiles_list (list): List of canonical SMILES strings to classify.\n",
    "    - batch_size (int): Number of SMILES per batch/job.\n",
    "    - save_interval (int): Save intermediate results every 'save_interval' batches.\n",
    "    - output_dir (str): Directory to save intermediate result files.\n",
    "    - max_retries (int): Maximum number of retries for failed batches.\n",
    "    - retry_delay (int): Delay between retries in seconds.\n",
    "    \n",
    "    Returns:\n",
    "    - saved_files (list): List of paths to the saved intermediate JSON files.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Split the SMILES list into batches\n",
    "    batches = chunk_tasks(smiles_list, batch_size)\n",
    "    total_batches = len(batches)\n",
    "    print(f\"Total number of batches to process: {total_batches}\")\n",
    "    logging.info(f\"Total number of batches to process: {total_batches}\")\n",
    "    \n",
    "    # Create Job instances for each batch\n",
    "    jobs = [Job(batch) for batch in batches]\n",
    "    \n",
    "    # Initialize Scheduler\n",
    "    scheduler = Scheduler(jobs)\n",
    "    \n",
    "    # Initialize counters\n",
    "    processed_batches = 0\n",
    "    saved_files = []\n",
    "    current_batch = 0\n",
    "    \n",
    "    # Initialize progress bar\n",
    "    pbar = tqdm(total=total_batches, desc=\"Processing Batches\")\n",
    "    \n",
    "    while scheduler.jobs:\n",
    "        try:\n",
    "            job = scheduler.jobs[0]\n",
    "            if job.query_id is None:\n",
    "                # Submit the job\n",
    "                job.submit()\n",
    "                logging.info(f\"Submitted Job {current_batch + 1}/{total_batches} with Query ID {job.query_id}\")\n",
    "                print(f\"Submitted Job {current_batch + 1}/{total_batches} with Query ID {job.query_id}\")\n",
    "                time.sleep(60)  # Wait before checking status\n",
    "            elif job.is_done:\n",
    "                # Parse and store the results\n",
    "                scheduler.results[job.query_id] = job.parse_results()\n",
    "                logging.info(f\"Job {current_batch + 1}/{total_batches} completed.\")\n",
    "                print(f\"Job {current_batch + 1}/{total_batches} completed.\")\n",
    "                scheduler.jobs.pop(0)\n",
    "                processed_batches += 1\n",
    "                current_batch += 1\n",
    "                pbar.update(1)\n",
    "                time.sleep(10)  # Short wait before processing next job\n",
    "                \n",
    "                # Save intermediate results every 'save_interval' batches\n",
    "                if processed_batches % save_interval == 0:\n",
    "                    intermediate_file = os.path.join(output_dir, f'intermediate_{processed_batches}.json')\n",
    "                    with open(intermediate_file, 'w') as f:\n",
    "                        json.dump(scheduler.results, f, indent=4)\n",
    "                    saved_files.append(intermediate_file)\n",
    "                    logging.info(f\"Saved intermediate results to {intermediate_file}\")\n",
    "                    print(f\"Saved intermediate results to {intermediate_file}\")\n",
    "            elif job.is_stale:\n",
    "                # Handle stale jobs\n",
    "                logging.warning(f\"Job {current_batch + 1}/{total_batches} is stale. Skipping.\")\n",
    "                print(f\"Job {current_batch + 1}/{total_batches} is stale. Skipping.\")\n",
    "                scheduler.results[job.query_id] = []\n",
    "                scheduler.jobs.pop(0)\n",
    "                processed_batches += 1\n",
    "                current_batch += 1\n",
    "                pbar.update(1)\n",
    "            else:\n",
    "                # Job is still running\n",
    "                time.sleep(60)  # Wait before rechecking\n",
    "        except urllib.error.HTTPError as e:\n",
    "            logging.error(f\"HTTPError encountered: {e}. Retrying Job {current_batch + 1}/{total_batches}.\")\n",
    "            print(f\"HTTPError encountered: {e}. Retrying Job {current_batch + 1}/{total_batches}.\")\n",
    "            if scheduler.retry < max_retries:\n",
    "                scheduler.retry += 1\n",
    "                logging.info(f\"Retrying Job {current_batch + 1}/{total_batches} after {retry_delay} seconds.\")\n",
    "                print(f\"Retrying Job {current_batch + 1}/{total_batches} after {retry_delay} seconds.\")\n",
    "                time.sleep(retry_delay)  # Wait before retrying\n",
    "            else:\n",
    "                logging.error(f\"Maximum retries reached for Job {current_batch + 1}/{total_batches}. Skipping.\")\n",
    "                print(f\"Maximum retries reached for Job {current_batch + 1}/{total_batches}. Skipping.\")\n",
    "                scheduler.jobs.pop(0)\n",
    "                scheduler.results[job.query_id] = []\n",
    "                processed_batches += 1\n",
    "                current_batch += 1\n",
    "                pbar.update(1)\n",
    "                scheduler.retry = 0  # Reset retry counter\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Unexpected error: {e}. Skipping Job {current_batch + 1}/{total_batches}.\")\n",
    "            print(f\"Unexpected error: {e}. Skipping Job {current_batch + 1}/{total_batches}.\")\n",
    "            scheduler.jobs.pop(0)\n",
    "            scheduler.results[job.query_id] = []\n",
    "            processed_batches += 1\n",
    "            current_batch += 1\n",
    "            pbar.update(1)\n",
    "    \n",
    "    pbar.close()\n",
    "    \n",
    "    # Save any remaining results after processing all jobs\n",
    "    if processed_batches % save_interval != 0:\n",
    "        intermediate_file = os.path.join(output_dir, f'intermediate_{processed_batches}.json')\n",
    "        with open(intermediate_file, 'w') as f:\n",
    "            json.dump(scheduler.results, f, indent=4)\n",
    "        saved_files.append(intermediate_file)\n",
    "        logging.info(f\"Saved final intermediate results to {intermediate_file}\")\n",
    "        print(f\"Saved final intermediate results to {intermediate_file}\")\n",
    "    \n",
    "    return saved_files"
   ],
   "id": "d7eebe14734d8865",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_existing_results(output_dir):\n",
    "    \"\"\"\n",
    "    Loads existing intermediate JSON files and returns a set of already processed SMILES.\n",
    "    \"\"\"\n",
    "    merged_results = {}\n",
    "    if not os.path.exists(output_dir):\n",
    "        return merged_results\n",
    "    for file in os.listdir(output_dir):\n",
    "        if file.startswith('intermediate_') and file.endswith('.json'):\n",
    "            with open(os.path.join(output_dir, file), 'r') as f:\n",
    "                data = json.load(f)\n",
    "                merged_results.update(data)\n",
    "    return merged_results"
   ],
   "id": "6061ede26d6bae07"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "bbe1fefbb2996c26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2d1308c683969d33"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a779e2d87ec4169b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T19:45:11.108363Z",
     "start_time": "2025-01-01T16:45:55.381412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the list of canonical SMILES\n",
    "canonical_smiles_list = smiles_df['Canonical_SMILES'].tolist()\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 100          # Number of SMILES per job\n",
    "save_interval = 20        # Save intermediate results every 20 batches\n",
    "output_dir = '/Users/macbook/CODE/PyClassyFire/data/intermediate_results/'\n",
    "max_retries = 3           # Maximum number of retries for failed batches\n",
    "retry_delay = 300         # Delay between retries in seconds (5 minutes)\n",
    "\n",
    "# Process the batches and save intermediate results with retry logic\n",
    "intermediate_files = process_batches_with_saving_and_retry(\n",
    "    smiles_list=canonical_smiles_list,\n",
    "    batch_size=batch_size,\n",
    "    save_interval=save_interval,\n",
    "    output_dir=output_dir,\n",
    "    max_retries=max_retries,\n",
    "    retry_delay=retry_delay\n",
    ")"
   ],
   "id": "9bb47ffa7a4b9dea",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of batches to process: 140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   0%|          | 0/140 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted Job 1/140 with Query ID 12021290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   1%|          | 1/140 [01:49<4:13:04, 109.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 1/140 completed.\n",
      "Submitted Job 2/140 with Query ID 12021291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   1%|▏         | 2/140 [03:52<4:29:52, 117.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 2/140 completed.\n",
      "Submitted Job 3/140 with Query ID 12021292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   2%|▏         | 3/140 [05:49<4:28:16, 117.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 3/140 completed.\n",
      "Submitted Job 4/140 with Query ID 12021293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   3%|▎         | 4/140 [07:49<4:27:57, 118.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 4/140 completed.\n",
      "Submitted Job 5/140 with Query ID 12021294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   4%|▎         | 5/140 [09:46<4:25:21, 117.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 5/140 completed.\n",
      "Submitted Job 6/140 with Query ID 12021295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   4%|▍         | 6/140 [11:44<4:23:34, 118.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 6/140 completed.\n",
      "Submitted Job 7/140 with Query ID 12021296\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   5%|▌         | 7/140 [13:53<4:29:34, 121.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 7/140 completed.\n",
      "Submitted Job 8/140 with Query ID 12021297\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   6%|▌         | 8/140 [16:06<4:35:05, 125.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 8/140 completed.\n",
      "Submitted Job 9/140 with Query ID 12021298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   6%|▋         | 9/140 [18:16<4:36:43, 126.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 9/140 completed.\n",
      "Submitted Job 10/140 with Query ID 12021299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   7%|▋         | 10/140 [20:30<4:39:13, 128.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 10/140 completed.\n",
      "Submitted Job 11/140 with Query ID 12021300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   8%|▊         | 11/140 [22:41<4:38:38, 129.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 11/140 completed.\n",
      "Submitted Job 12/140 with Query ID 12021301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   9%|▊         | 12/140 [24:56<4:39:42, 131.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 12/140 completed.\n",
      "Submitted Job 13/140 with Query ID 12021302\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:   9%|▉         | 13/140 [27:08<4:38:26, 131.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 13/140 completed.\n",
      "Submitted Job 14/140 with Query ID 12021303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  10%|█         | 14/140 [29:18<4:34:52, 130.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 14/140 completed.\n",
      "Submitted Job 15/140 with Query ID 12021304\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  11%|█         | 15/140 [31:25<4:30:15, 129.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 15/140 completed.\n",
      "Submitted Job 16/140 with Query ID 12021305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  11%|█▏        | 16/140 [33:32<4:26:20, 128.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 16/140 completed.\n",
      "Submitted Job 17/140 with Query ID 12021306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  12%|█▏        | 17/140 [35:42<4:25:14, 129.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 17/140 completed.\n",
      "Submitted Job 18/140 with Query ID 12021308\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  13%|█▎        | 18/140 [38:26<4:43:51, 139.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 18/140 completed.\n",
      "Submitted Job 19/140 with Query ID 12021309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  14%|█▎        | 19/140 [40:38<4:37:23, 137.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021309.json. Skipping Job 19/140.\n",
      "Submitted Job 20/140 with Query ID 12021311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  14%|█▍        | 20/140 [42:55<4:34:30, 137.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 20/140 completed.\n",
      "Saved intermediate results to /Users/macbook/CODE/PyClassyFire/data/intermediate_results/intermediate_20.json\n",
      "Submitted Job 21/140 with Query ID 12021312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  15%|█▌        | 21/140 [45:08<4:30:01, 136.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021312.json. Skipping Job 21/140.\n",
      "Submitted Job 22/140 with Query ID 12021313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  16%|█▌        | 22/140 [47:13<4:20:56, 132.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021313.json. Skipping Job 22/140.\n",
      "Submitted Job 23/140 with Query ID 12021314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  16%|█▋        | 23/140 [49:34<4:23:38, 135.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 23/140 completed.\n",
      "Submitted Job 24/140 with Query ID 12021316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  17%|█▋        | 24/140 [52:05<4:30:34, 139.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 24/140 completed.\n",
      "Submitted Job 25/140 with Query ID 12021319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  18%|█▊        | 25/140 [54:28<4:30:04, 140.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 25/140 completed.\n",
      "Submitted Job 26/140 with Query ID 12021322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  19%|█▊        | 26/140 [57:04<4:35:57, 145.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 26/140 completed.\n",
      "Submitted Job 27/140 with Query ID 12021325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  19%|█▉        | 27/140 [59:44<4:41:59, 149.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 27/140 completed.\n",
      "Submitted Job 28/140 with Query ID 12021328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  20%|██        | 28/140 [1:01:56<4:29:33, 144.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021328.json. Skipping Job 28/140.\n",
      "Submitted Job 29/140 with Query ID 12021331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  21%|██        | 29/140 [1:04:01<4:16:44, 138.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021331.json. Skipping Job 29/140.\n",
      "Submitted Job 30/140 with Query ID 12021333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  21%|██▏       | 30/140 [1:06:25<4:16:51, 140.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 30/140 completed.\n",
      "Submitted Job 31/140 with Query ID 12021337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  22%|██▏       | 31/140 [1:08:39<4:11:21, 138.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021337.json. Skipping Job 31/140.\n",
      "Submitted Job 32/140 with Query ID 12021338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  23%|██▎       | 32/140 [1:11:04<4:12:23, 140.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 32/140 completed.\n",
      "Submitted Job 33/140 with Query ID 12021341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  24%|██▎       | 33/140 [1:13:16<4:06:00, 137.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021341.json. Skipping Job 33/140.\n",
      "Submitted Job 34/140 with Query ID 12021343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  24%|██▍       | 34/140 [1:15:20<3:55:59, 133.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021343.json. Skipping Job 34/140.\n",
      "Submitted Job 35/140 with Query ID 12021345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  25%|██▌       | 35/140 [1:17:21<3:47:33, 130.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021345.json. Skipping Job 35/140.\n",
      "Submitted Job 36/140 with Query ID 12021346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  26%|██▌       | 36/140 [1:19:24<3:41:33, 127.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021346.json. Skipping Job 36/140.\n",
      "Submitted Job 37/140 with Query ID 12021349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  26%|██▋       | 37/140 [1:21:29<3:38:09, 127.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021349.json. Skipping Job 37/140.\n",
      "Submitted Job 38/140 with Query ID 12021353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  27%|██▋       | 38/140 [1:23:58<3:47:11, 133.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 38/140 completed.\n",
      "Submitted Job 39/140 with Query ID 12021356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  28%|██▊       | 39/140 [1:26:31<3:54:48, 139.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 39/140 completed.\n",
      "Submitted Job 40/140 with Query ID 12021359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  29%|██▊       | 40/140 [1:28:44<3:49:08, 137.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021359.json. Skipping Job 40/140.\n",
      "Submitted Job 41/140 with Query ID 12021362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  29%|██▉       | 41/140 [1:30:47<3:39:21, 132.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021362.json. Skipping Job 41/140.\n",
      "Submitted Job 42/140 with Query ID 12021365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  30%|███       | 42/140 [1:33:15<3:44:51, 137.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 42/140 completed.\n",
      "Submitted Job 43/140 with Query ID 12021371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  31%|███       | 43/140 [1:35:32<3:41:56, 137.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 43/140 completed.\n",
      "Submitted Job 44/140 with Query ID 12021376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  31%|███▏      | 44/140 [1:38:04<3:46:52, 141.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 44/140 completed.\n",
      "Submitted Job 45/140 with Query ID 12021377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  32%|███▏      | 45/140 [1:40:40<3:51:14, 146.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 45/140 completed.\n",
      "Submitted Job 46/140 with Query ID 12021378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  33%|███▎      | 46/140 [1:42:58<3:45:08, 143.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 46/140 completed.\n",
      "Submitted Job 47/140 with Query ID 12021379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  34%|███▎      | 47/140 [1:45:26<3:44:27, 144.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 47/140 completed.\n",
      "Submitted Job 48/140 with Query ID 12021380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  34%|███▍      | 48/140 [1:48:00<3:46:18, 147.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 48/140 completed.\n",
      "Submitted Job 49/140 with Query ID 12021381\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  35%|███▌      | 49/140 [1:49:36<3:20:36, 132.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 500 Server Error: Internal Server Error for url: http://classyfire.wishartlab.com/queries/12021381.json. Skipping Job 49/140.\n",
      "Submitted Job 50/140 with Query ID 12021382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  36%|███▌      | 50/140 [1:51:57<3:22:20, 134.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 50/140 completed.\n",
      "Submitted Job 51/140 with Query ID 12021383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  36%|███▋      | 51/140 [1:53:50<3:10:25, 128.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 500 Server Error: Internal Server Error for url: http://classyfire.wishartlab.com/queries/12021383.json. Skipping Job 51/140.\n",
      "Submitted Job 52/140 with Query ID 12021384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  37%|███▋      | 52/140 [1:55:50<3:04:18, 125.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 52/140 completed.\n",
      "Submitted Job 53/140 with Query ID 12021386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  38%|███▊      | 53/140 [1:58:36<3:19:45, 137.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 53/140 completed.\n",
      "Submitted Job 54/140 with Query ID 12021388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  39%|███▊      | 54/140 [2:00:53<3:17:04, 137.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021388.json. Skipping Job 54/140.\n",
      "Submitted Job 55/140 with Query ID 12021389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  39%|███▉      | 55/140 [2:03:27<3:21:50, 142.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 55/140 completed.\n",
      "Submitted Job 56/140 with Query ID 12021390\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  40%|████      | 56/140 [2:05:40<3:15:45, 139.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021390.json. Skipping Job 56/140.\n",
      "Submitted Job 57/140 with Query ID 12021391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  41%|████      | 57/140 [2:07:15<2:54:51, 126.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 500 Server Error: Internal Server Error for url: http://classyfire.wishartlab.com/queries/12021391.json. Skipping Job 57/140.\n",
      "Submitted Job 58/140 with Query ID 12021392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  41%|████▏     | 58/140 [2:09:18<2:51:11, 125.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021392.json. Skipping Job 58/140.\n",
      "Submitted Job 59/140 with Query ID 12021393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  42%|████▏     | 59/140 [2:11:20<2:47:43, 124.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021393.json. Skipping Job 59/140.\n",
      "Submitted Job 60/140 with Query ID 12021394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  43%|████▎     | 60/140 [2:13:23<2:45:18, 123.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021394.json. Skipping Job 60/140.\n",
      "Submitted Job 61/140 with Query ID 12021395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  44%|████▎     | 61/140 [2:15:28<2:43:37, 124.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021395.json. Skipping Job 61/140.\n",
      "Submitted Job 62/140 with Query ID 12021396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  44%|████▍     | 62/140 [2:17:33<2:41:50, 124.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021396.json. Skipping Job 62/140.\n",
      "Submitted Job 63/140 with Query ID 12021397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  45%|████▌     | 63/140 [2:19:35<2:38:52, 123.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021397.json. Skipping Job 63/140.\n",
      "Submitted Job 64/140 with Query ID 12021398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  46%|████▌     | 64/140 [2:22:09<2:48:20, 132.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 64/140 completed.\n",
      "Submitted Job 65/140 with Query ID 12021399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  46%|████▋     | 65/140 [2:24:23<2:46:18, 133.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021399.json. Skipping Job 65/140.\n",
      "Submitted Job 66/140 with Query ID 12021400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  47%|████▋     | 66/140 [2:26:53<2:50:21, 138.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 66/140 completed.\n",
      "Submitted Job 67/140 with Query ID 12021401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  48%|████▊     | 67/140 [2:29:31<2:55:14, 144.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 67/140 completed.\n",
      "Submitted Job 68/140 with Query ID 12021402\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  49%|████▊     | 68/140 [2:32:12<2:59:06, 149.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job 68/140 completed.\n",
      "Submitted Job 69/140 with Query ID 12021403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  49%|████▉     | 69/140 [2:34:25<2:50:56, 144.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021403.json. Skipping Job 69/140.\n",
      "Submitted Job 70/140 with Query ID 12021404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  50%|█████     | 70/140 [2:36:33<2:42:44, 139.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021404.json. Skipping Job 70/140.\n",
      "Submitted Job 71/140 with Query ID 12021405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  51%|█████     | 71/140 [2:38:38<2:35:20, 135.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: 504 Server Error: Gateway Time-out for url: http://classyfire.wishartlab.com/queries/12021405.json. Skipping Job 71/140.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Batches:  51%|█████▏    | 72/140 [2:39:51<2:12:04, 116.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected error: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response')). Skipping Job 72/140.\n",
      "Submitted Job 73/140 with Query ID 12021406\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 12\u001B[0m\n\u001B[1;32m      9\u001B[0m retry_delay \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m300\u001B[39m         \u001B[38;5;66;03m# Delay between retries in seconds (5 minutes)\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Process the batches and save intermediate results with retry logic\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m intermediate_files \u001B[38;5;241m=\u001B[39m \u001B[43mprocess_batches_with_saving_and_retry\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     13\u001B[0m \u001B[43m    \u001B[49m\u001B[43msmiles_list\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcanonical_smiles_list\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43msave_interval\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msave_interval\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43moutput_dir\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moutput_dir\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     17\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmax_retries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     18\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretry_delay\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretry_delay\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[8], line 56\u001B[0m, in \u001B[0;36mprocess_batches_with_saving_and_retry\u001B[0;34m(smiles_list, batch_size, save_interval, output_dir, max_retries, retry_delay)\u001B[0m\n\u001B[1;32m     54\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSubmitted Job \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_batch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_batches\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m with Query ID \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mjob\u001B[38;5;241m.\u001B[39mquery_id\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     55\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m60\u001B[39m)  \u001B[38;5;66;03m# Wait before checking status\u001B[39;00m\n\u001B[0;32m---> 56\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_done\u001B[49m:\n\u001B[1;32m     57\u001B[0m     \u001B[38;5;66;03m# Parse and store the results\u001B[39;00m\n\u001B[1;32m     58\u001B[0m     scheduler\u001B[38;5;241m.\u001B[39mresults[job\u001B[38;5;241m.\u001B[39mquery_id] \u001B[38;5;241m=\u001B[39m job\u001B[38;5;241m.\u001B[39mparse_results()\n\u001B[1;32m     59\u001B[0m     logging\u001B[38;5;241m.\u001B[39minfo(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mJob \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcurrent_batch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtotal_batches\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m completed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/CODE/PyClassyFire/classyfire_cli/src/batch.py:22\u001B[0m, in \u001B[0;36mJob.is_done\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[38;5;129m@property\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_done\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n\u001B[0;32m---> 22\u001B[0m     result \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[43mget_results\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_id\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     23\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mclassification_status\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mDone\u001B[39m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[0;32m~/CODE/PyClassyFire/classyfire_cli/src/api.py:46\u001B[0m, in \u001B[0;36mget_results\u001B[0;34m(query_id, return_format)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_results\u001B[39m(query_id, return_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     32\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Given a query_id, fetch the classification results.\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    :param query_id: A numeric query id returned at time of query submission\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m/queries/\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_format\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreturn_format\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     r\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/sessions.py:746\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    743\u001B[0m         \u001B[38;5;28;01mpass\u001B[39;00m\n\u001B[1;32m    745\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n\u001B[0;32m--> 746\u001B[0m     \u001B[43mr\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcontent\u001B[49m\n\u001B[1;32m    748\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m r\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/models.py:902\u001B[0m, in \u001B[0;36mResponse.content\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    900\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    901\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 902\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content \u001B[38;5;241m=\u001B[39m \u001B[38;5;124;43mb\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43miter_content\u001B[49m\u001B[43m(\u001B[49m\u001B[43mCONTENT_CHUNK_SIZE\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    904\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_content_consumed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m    905\u001B[0m \u001B[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001B[39;00m\n\u001B[1;32m    906\u001B[0m \u001B[38;5;66;03m# since we exhausted the data.\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/models.py:820\u001B[0m, in \u001B[0;36mResponse.iter_content.<locals>.generate\u001B[0;34m()\u001B[0m\n\u001B[1;32m    818\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstream\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m    819\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 820\u001B[0m         \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mraw\u001B[38;5;241m.\u001B[39mstream(chunk_size, decode_content\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m    821\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m ProtocolError \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    822\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m ChunkedEncodingError(e)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/response.py:1063\u001B[0m, in \u001B[0;36mHTTPResponse.stream\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1047\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1048\u001B[0m \u001B[38;5;124;03mA generator wrapper for the read() method. A call will block until\u001B[39;00m\n\u001B[1;32m   1049\u001B[0m \u001B[38;5;124;03m``amt`` bytes have been read from the connection or until the\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1060\u001B[0m \u001B[38;5;124;03m    'content-encoding' header.\u001B[39;00m\n\u001B[1;32m   1061\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1062\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunked \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_chunked_reads():\n\u001B[0;32m-> 1063\u001B[0m     \u001B[38;5;28;01myield from\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mread_chunked(amt, decode_content\u001B[38;5;241m=\u001B[39mdecode_content)\n\u001B[1;32m   1064\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1065\u001B[0m     \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fp_closed(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp) \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decoded_buffer) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/response.py:1222\u001B[0m, in \u001B[0;36mHTTPResponse.read_chunked\u001B[0;34m(self, amt, decode_content)\u001B[0m\n\u001B[1;32m   1220\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m   1221\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n\u001B[0;32m-> 1222\u001B[0m chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle_chunk\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1223\u001B[0m decoded \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_decode(\n\u001B[1;32m   1224\u001B[0m     chunk, decode_content\u001B[38;5;241m=\u001B[39mdecode_content, flush_decoder\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[1;32m   1225\u001B[0m )\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m decoded:\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/response.py:1168\u001B[0m, in \u001B[0;36mHTTPResponse._handle_chunk\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m   1166\u001B[0m     returned_chunk \u001B[38;5;241m=\u001B[39m value\n\u001B[1;32m   1167\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:  \u001B[38;5;66;03m# amt > self.chunk_left\u001B[39;00m\n\u001B[0;32m-> 1168\u001B[0m     returned_chunk \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_safe_read\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mchunk_left\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# type: ignore[union-attr]\u001B[39;00m\n\u001B[1;32m   1169\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_fp\u001B[38;5;241m.\u001B[39m_safe_read(\u001B[38;5;241m2\u001B[39m)  \u001B[38;5;66;03m# type: ignore[union-attr] # Toss the CRLF at the end of the chunk.\u001B[39;00m\n\u001B[1;32m   1170\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchunk_left \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/http/client.py:631\u001B[0m, in \u001B[0;36mHTTPResponse._safe_read\u001B[0;34m(self, amt)\u001B[0m\n\u001B[1;32m    624\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_safe_read\u001B[39m(\u001B[38;5;28mself\u001B[39m, amt):\n\u001B[1;32m    625\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Read the number of bytes requested.\u001B[39;00m\n\u001B[1;32m    626\u001B[0m \n\u001B[1;32m    627\u001B[0m \u001B[38;5;124;03m    This function should be used when <amt> bytes \"should\" be present for\u001B[39;00m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;124;03m    reading. If the bytes are truly not available (due to EOF), then the\u001B[39;00m\n\u001B[1;32m    629\u001B[0m \u001B[38;5;124;03m    IncompleteRead exception can be used to detect the problem.\u001B[39;00m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread\u001B[49m\u001B[43m(\u001B[49m\u001B[43mamt\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m<\u001B[39m amt:\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m IncompleteRead(data, amt\u001B[38;5;241m-\u001B[39m\u001B[38;5;28mlen\u001B[39m(data))\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/socket.py:717\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    716\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 717\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    718\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    719\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def merge_intermediate_results(intermediate_files):\n",
    "    \"\"\"\n",
    "    Merges multiple intermediate JSON result files into a single dictionary.\n",
    "\n",
    "    Parameters:\n",
    "    - intermediate_files (list): List of file paths to intermediate JSON files.\n",
    "\n",
    "    Returns:\n",
    "    - merged_results (dict): Merged classification results.\n",
    "    \"\"\"\n",
    "    merged_results = {}\n",
    "    for file in intermediate_files:\n",
    "        try:\n",
    "            with open(file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "                merged_results.update(data)\n",
    "            logging.info(f\"Successfully merged results from {file}\")\n",
    "            print(f\"Successfully merged results from {file}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error merging results from {file}: {e}\")\n",
    "            print(f\"Error merging results from {file}: {e}\")\n",
    "    return merged_results"
   ],
   "id": "b11b30d762792b7b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge all intermediate results\n",
    "merged_results = merge_intermediate_results(intermediate_files)\n",
    "\n",
    "# Display the number of classified SMILES\n",
    "classified_count = len(merged_results)\n",
    "print(f\"Total number of classified SMILES: {classified_count}\")"
   ],
   "id": "a00621491e034c38"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Convert the merged results dictionary to a DataFrame\n",
    "# The dictionary keys are canonical SMILES, and values are classification details\n",
    "results_df = pd.DataFrame.from_dict(merged_results, orient='index')\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(columns={'index': 'Canonical_SMILES'}, inplace=True)\n",
    "\n",
    "# Display the first few entries of the results\n",
    "results_df.head()"
   ],
   "id": "8493792452e163a8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge the classification results with the original SMILES DataFrame\n",
    "annotated_df = pd.merge(smiles_df, results_df, on='Canonical_SMILES', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "annotated_df.head()"
   ],
   "id": "65ea0ae0b173b7d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check for any SMILES that did not receive a classification\n",
    "unclassified = annotated_df['superclass'].isnull().sum()\n",
    "print(f\"Number of SMILES without classification: {unclassified}\")\n",
    "\n",
    "# Optionally, handle unclassified SMILES (e.g., mark as 'Unknown')\n",
    "annotated_df['superclass'].fillna('Unknown', inplace=True)\n",
    "annotated_df['class'].fillna('Unknown', inplace=True)\n",
    "annotated_df['subclass'].fillna('Unknown', inplace=True)"
   ],
   "id": "2bca5b8bdfa9e77f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the output path for the annotated data\n",
    "final_output_path = '/Users/macbook/CODE/PyClassyFire/data/classified_smiles.tsv'\n",
    "\n",
    "# Save the annotated DataFrame to a TSV file\n",
    "annotated_df.to_csv(final_output_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Annotated data has been saved to {final_output_path}\")"
   ],
   "id": "d40de108bff0d174"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "526277c51edb36ec"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "519532d392eb86e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2d6e2ab44ef34e26"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c7975a504b0bde0f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:17:29.299894Z",
     "start_time": "2025-01-01T16:17:29.296084Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Extract the list of canonical SMILES\n",
    "canonical_smiles_list = smiles_df['Canonical_SMILES'].tolist()\n",
    "\n",
    "# Define the batch size (number of SMILES per job)\n",
    "batch_size = 100  # Adjust based on API limitations and performance\n",
    "\n",
    "# Create batches using the chunk_tasks utility function\n",
    "batches = chunk_tasks(canonical_smiles_list, batch_size)\n",
    "\n",
    "# Create Job instances for each batch\n",
    "jobs = [Job(batch) for batch in batches]\n",
    "\n",
    "print(f\"Total number of jobs created: {len(jobs)}\")"
   ],
   "id": "d33bd99300af4cef",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of jobs created: 140\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:17:45.254568Z",
     "start_time": "2025-01-01T16:17:45.252077Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize the Scheduler with the list of jobs\n",
    "scheduler = Scheduler(jobs)"
   ],
   "id": "d77ec92b787d77b1",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-01T16:34:53.840648Z",
     "start_time": "2025-01-01T16:17:54.688728Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Start the classification process\n",
    "print(\"Submitting classification jobs to the ClassyFire API...\")\n",
    "scheduler.run()\n",
    "print(\"All jobs have been processed.\")"
   ],
   "id": "5a5386e4a1093fa1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting classification jobs to the ClassyFire API...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 6/140 [14:58<5:26:44, 146.30s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Start the classification process\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSubmitting classification jobs to the ClassyFire API...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAll jobs have been processed.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/CODE/PyClassyFire/classyfire_cli/src/batch.py:54\u001B[0m, in \u001B[0;36mScheduler.run\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m job\u001B[38;5;241m.\u001B[39mis_done:\n\u001B[1;32m     53\u001B[0m     time\u001B[38;5;241m.\u001B[39msleep(\u001B[38;5;241m10\u001B[39m)\n\u001B[0;32m---> 54\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresults[job\u001B[38;5;241m.\u001B[39mquery_id] \u001B[38;5;241m=\u001B[39m \u001B[43mjob\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparse_results\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     55\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mjobs\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m     56\u001B[0m     pbar\u001B[38;5;241m.\u001B[39mupdate(\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m~/CODE/PyClassyFire/classyfire_cli/src/batch.py:30\u001B[0m, in \u001B[0;36mJob.parse_results\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mparse_results\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28mlist\u001B[39m[\u001B[38;5;28mdict\u001B[39m]:\n\u001B[0;32m---> 30\u001B[0m     result \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mloads(\u001B[43mget_results\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mquery_id\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     31\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m result[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mentities\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n",
      "File \u001B[0;32m~/CODE/PyClassyFire/classyfire_cli/src/api.py:46\u001B[0m, in \u001B[0;36mget_results\u001B[0;34m(query_id, return_format)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_results\u001B[39m(query_id, return_format\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mjson\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     32\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Given a query_id, fetch the classification results.\u001B[39;00m\n\u001B[1;32m     33\u001B[0m \n\u001B[1;32m     34\u001B[0m \u001B[38;5;124;03m    :param query_id: A numeric query id returned at time of query submission\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     44\u001B[0m \n\u001B[1;32m     45\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 46\u001B[0m     r \u001B[38;5;241m=\u001B[39m \u001B[43mrequests\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m/queries/\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m.\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_id\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_format\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[43m                     \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mContent-Type\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mapplication/\u001B[39;49m\u001B[38;5;132;43;01m%s\u001B[39;49;00m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m%\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mreturn_format\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     48\u001B[0m     r\u001B[38;5;241m.\u001B[39mraise_for_status()\n\u001B[1;32m     49\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m r\u001B[38;5;241m.\u001B[39mtext\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/api.py:73\u001B[0m, in \u001B[0;36mget\u001B[0;34m(url, params, **kwargs)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget\u001B[39m(url, params\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[1;32m     63\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Sends a GET request.\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \n\u001B[1;32m     65\u001B[0m \u001B[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     70\u001B[0m \u001B[38;5;124;03m    :rtype: requests.Response\u001B[39;00m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m---> 73\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mget\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mparams\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mparams\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/api.py:59\u001B[0m, in \u001B[0;36mrequest\u001B[0;34m(method, url, **kwargs)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001B[39;00m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001B[39;00m\n\u001B[1;32m     57\u001B[0m \u001B[38;5;66;03m# cases, and look like a memory leak in others.\u001B[39;00m\n\u001B[1;32m     58\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m sessions\u001B[38;5;241m.\u001B[39mSession() \u001B[38;5;28;01mas\u001B[39;00m session:\n\u001B[0;32m---> 59\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43msession\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/sessions.py:589\u001B[0m, in \u001B[0;36mSession.request\u001B[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001B[0m\n\u001B[1;32m    584\u001B[0m send_kwargs \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    585\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtimeout\u001B[39m\u001B[38;5;124m\"\u001B[39m: timeout,\n\u001B[1;32m    586\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow_redirects\u001B[39m\u001B[38;5;124m\"\u001B[39m: allow_redirects,\n\u001B[1;32m    587\u001B[0m }\n\u001B[1;32m    588\u001B[0m send_kwargs\u001B[38;5;241m.\u001B[39mupdate(settings)\n\u001B[0;32m--> 589\u001B[0m resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43msend_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    591\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m resp\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/sessions.py:703\u001B[0m, in \u001B[0;36mSession.send\u001B[0;34m(self, request, **kwargs)\u001B[0m\n\u001B[1;32m    700\u001B[0m start \u001B[38;5;241m=\u001B[39m preferred_clock()\n\u001B[1;32m    702\u001B[0m \u001B[38;5;66;03m# Send the request\u001B[39;00m\n\u001B[0;32m--> 703\u001B[0m r \u001B[38;5;241m=\u001B[39m \u001B[43madapter\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msend\u001B[49m\u001B[43m(\u001B[49m\u001B[43mrequest\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    705\u001B[0m \u001B[38;5;66;03m# Total elapsed time of the request (approximately)\u001B[39;00m\n\u001B[1;32m    706\u001B[0m elapsed \u001B[38;5;241m=\u001B[39m preferred_clock() \u001B[38;5;241m-\u001B[39m start\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/requests/adapters.py:667\u001B[0m, in \u001B[0;36mHTTPAdapter.send\u001B[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001B[0m\n\u001B[1;32m    664\u001B[0m     timeout \u001B[38;5;241m=\u001B[39m TimeoutSauce(connect\u001B[38;5;241m=\u001B[39mtimeout, read\u001B[38;5;241m=\u001B[39mtimeout)\n\u001B[1;32m    666\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 667\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43murlopen\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    668\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmethod\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    669\u001B[0m \u001B[43m        \u001B[49m\u001B[43murl\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    670\u001B[0m \u001B[43m        \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    671\u001B[0m \u001B[43m        \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mrequest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    672\u001B[0m \u001B[43m        \u001B[49m\u001B[43mredirect\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    673\u001B[0m \u001B[43m        \u001B[49m\u001B[43massert_same_host\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    674\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    675\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m    676\u001B[0m \u001B[43m        \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmax_retries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    677\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    678\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    679\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    681\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (ProtocolError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[1;32m    682\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m(err, request\u001B[38;5;241m=\u001B[39mrequest)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/connectionpool.py:787\u001B[0m, in \u001B[0;36mHTTPConnectionPool.urlopen\u001B[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001B[0m\n\u001B[1;32m    784\u001B[0m response_conn \u001B[38;5;241m=\u001B[39m conn \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m release_conn \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    786\u001B[0m \u001B[38;5;66;03m# Make the request on the HTTPConnection object\u001B[39;00m\n\u001B[0;32m--> 787\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_request\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    788\u001B[0m \u001B[43m    \u001B[49m\u001B[43mconn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    789\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmethod\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    790\u001B[0m \u001B[43m    \u001B[49m\u001B[43murl\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    791\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtimeout_obj\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    792\u001B[0m \u001B[43m    \u001B[49m\u001B[43mbody\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mbody\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    793\u001B[0m \u001B[43m    \u001B[49m\u001B[43mheaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mheaders\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    794\u001B[0m \u001B[43m    \u001B[49m\u001B[43mchunked\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunked\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    795\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretries\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mretries\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    796\u001B[0m \u001B[43m    \u001B[49m\u001B[43mresponse_conn\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mresponse_conn\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    797\u001B[0m \u001B[43m    \u001B[49m\u001B[43mpreload_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpreload_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    798\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdecode_content\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdecode_content\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    799\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mresponse_kw\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    800\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    802\u001B[0m \u001B[38;5;66;03m# Everything went great!\u001B[39;00m\n\u001B[1;32m    803\u001B[0m clean_exit \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/connectionpool.py:534\u001B[0m, in \u001B[0;36mHTTPConnectionPool._make_request\u001B[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001B[0m\n\u001B[1;32m    532\u001B[0m \u001B[38;5;66;03m# Receive the response from the server\u001B[39;00m\n\u001B[1;32m    533\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 534\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[43mconn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    535\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m (BaseSSLError, \u001B[38;5;167;01mOSError\u001B[39;00m) \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    536\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raise_timeout(err\u001B[38;5;241m=\u001B[39me, url\u001B[38;5;241m=\u001B[39murl, timeout_value\u001B[38;5;241m=\u001B[39mread_timeout)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/site-packages/urllib3/connection.py:516\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    513\u001B[0m _shutdown \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msock, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshutdown\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[1;32m    515\u001B[0m \u001B[38;5;66;03m# Get the response from http.client.HTTPConnection\u001B[39;00m\n\u001B[0;32m--> 516\u001B[0m httplib_response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mgetresponse\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    519\u001B[0m     assert_header_parsing(httplib_response\u001B[38;5;241m.\u001B[39mmsg)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/http/client.py:1375\u001B[0m, in \u001B[0;36mHTTPConnection.getresponse\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1373\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1374\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1375\u001B[0m         \u001B[43mresponse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbegin\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1376\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mConnectionError\u001B[39;00m:\n\u001B[1;32m   1377\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/http/client.py:318\u001B[0m, in \u001B[0;36mHTTPResponse.begin\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    316\u001B[0m \u001B[38;5;66;03m# read until we get a non-100 response\u001B[39;00m\n\u001B[1;32m    317\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 318\u001B[0m     version, status, reason \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_read_status\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m status \u001B[38;5;241m!=\u001B[39m CONTINUE:\n\u001B[1;32m    320\u001B[0m         \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/http/client.py:279\u001B[0m, in \u001B[0;36mHTTPResponse._read_status\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    278\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_read_status\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m--> 279\u001B[0m     line \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreadline\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_MAXLINE\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124miso-8859-1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    280\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(line) \u001B[38;5;241m>\u001B[39m _MAXLINE:\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m LineTooLong(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstatus line\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/UTILS/anaconda3/envs/classyfire_env/lib/python3.10/socket.py:717\u001B[0m, in \u001B[0;36mSocketIO.readinto\u001B[0;34m(self, b)\u001B[0m\n\u001B[1;32m    715\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[1;32m    716\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 717\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_sock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrecv_into\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    718\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m timeout:\n\u001B[1;32m    719\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_timeout_occurred \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Export the results from the Scheduler\n",
    "classification_results = scheduler.export()\n",
    "\n",
    "# Convert the results dictionary to a DataFrame\n",
    "# The dictionary keys are canonical SMILES, and values are classification details\n",
    "results_df = pd.DataFrame.from_dict(classification_results, orient='index')\n",
    "results_df.reset_index(inplace=True)\n",
    "results_df.rename(columns={'index': 'Canonical_SMILES'}, inplace=True)\n",
    "\n",
    "# Display the first few entries of the results\n",
    "results_df.head()"
   ],
   "id": "700262fd251dc3e0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Merge the classification results with the original SMILES DataFrame\n",
    "annotated_df = pd.merge(smiles_df, results_df, on='Canonical_SMILES', how='left')\n",
    "\n",
    "# Display the merged DataFrame\n",
    "annotated_df.head()"
   ],
   "id": "d7e79d8d7777587d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Check for any SMILES that did not receive a classification\n",
    "unclassified = annotated_df['superclass'].isnull().sum()\n",
    "print(f\"Number of SMILES without classification: {unclassified}\")\n",
    "\n",
    "# Optionally, handle unclassified SMILES (e.g., mark as 'Unknown')\n",
    "annotated_df['superclass'].fillna('Unknown', inplace=True)\n",
    "annotated_df['class'].fillna('Unknown', inplace=True)\n",
    "annotated_df['subclass'].fillna('Unknown', inplace=True)"
   ],
   "id": "fbc3dd4baea4b52b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Define the output path for the annotated data\n",
    "output_file_path = '../data/classified_smiles.tsv'\n",
    "\n",
    "# Save the annotated DataFrame to a TSV file\n",
    "annotated_df.to_csv(output_file_path, sep='\\t', index=False)\n",
    "\n",
    "print(f\"Annotated data has been saved to {output_file_path}\")"
   ],
   "id": "1d2e7940b156e40e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c3749dd4dc6f47ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "1258ae2af314c20d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
