{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# PyClassyFire Tutorial: Classifying Chemical Compounds Using the ClassyFire API\n",
    "\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Welcome to the **PyClassyFire** tutorial! This guide will walk you through the process of classifying a large set of chemical compounds using the [ClassyFire](http://classyfire.wishartlab.com/) API.\n",
    "\n",
    "By the end of this tutorial, you'll be able to:\n",
    "\n",
    "1. **Preprocess your SMILES data**: Prepare your unique SMILES strings for classification.\n",
    "2. **Submit classification jobs**: Use the `PyClassyFire` package to send your data to the ClassyFire API.\n",
    "3. **Retrieve and process results**: Collect the classification results and merge them with your original data.\n",
    "4. **Save the annotated data**: Store the enriched dataset.\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "Before diving into the tutorial, ensure you have the following:\n",
    "\n",
    "- **Conda Environment**: A Conda environment named `pyclassyfire_env` with all necessary dependencies installed.\n",
    "- **PyClassyFire Package**: Installed and accessible within your Conda environment.\n",
    "- **Unique SMILES Data**: A file containing SMILES strings, exampled can be taken from sample_data/sample_smiles.tsv.\n",
    "\n",
    "**Note:** This tutorial assumes that the Conda environment are already set up. If not, please refer to the [repository's README](https://github.com/Jozefov/PyClassyFire) for setup instructions."
   ],
   "id": "82b5bab971f2733b"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:16.253214Z",
     "start_time": "2025-01-11T06:11:15.913001Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "from pyclassyfire.src.utils import MoleCule, load_existing_results"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Before classification, you need to prepare your SMILES data. This involves loading the data from a TSV file and ensuring it’s clean and ready for processing.",
   "id": "d8669a2c69842989"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:16.276556Z",
     "start_time": "2025-01-11T06:11:16.264945Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Define paths\n",
    "smiles_file_path = '../sample_data/sample_smiles.tsv'\n",
    "output_dir = '../sample_data/output'\n",
    "intermediate_files_path = '../sample_data/output/intermediate_files'\n",
    "final_output_path = '../sample_data/output/output.json'\n",
    "\n",
    "# Load SMILES data\n",
    "# The TSV file may or may not have a header. We load it without assuming a header.\n",
    "smiles_df = pd.read_csv(smiles_file_path, sep='\\t', header=None, names=['SMILES']).dropna()\n",
    "\n",
    "# Check if the first row is a header (i.e., 'SMILES') and skip it if so\n",
    "if smiles_df.iloc[0]['SMILES'].strip().upper() == 'SMILES':\n",
    "    print(\"Header detected. Skipping the first row.\")\n",
    "    smiles_df = smiles_df.iloc[1:].reset_index(drop=True)\n",
    "else:\n",
    "    print(\"No header detected. Proceeding with all SMILES.\")\n",
    "    \n",
    "# Display the first few entries\n",
    "smiles_df.head()"
   ],
   "id": "6545871a47e06cba",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header detected. Skipping the first row.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                              SMILES\n",
       "0          COC1=C(C=C(C=C1)Br)CNC23CC4CC(C2)CC(C4)C3\n",
       "1  CCOC1=CC=C(C=C1)S(=O)(=O)[C@H]2CS(=O)(=O)C[C@@...\n",
       "2  CC1=C(C(N2C(=O)CCSC2=N1)C3=C(C=C(C=C3)Cl)Cl)C(...\n",
       "3  C1=CC(=C(C=C1COC(=O)C2=CC(=C(C=C2)O)O)O)O[C@H]...\n",
       "4  C[C@@H]1CCC[C@@H](N1CCCC(C2=CC=CC=C2)(C3=CC=CC..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMILES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COC1=C(C=C(C=C1)Br)CNC23CC4CC(C2)CC(C4)C3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CCOC1=CC=C(C=C1)S(=O)(=O)[C@H]2CS(=O)(=O)C[C@@...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CC1=C(C(N2C(=O)CCSC2=N1)C3=C(C=C(C=C3)Cl)Cl)C(...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C1=CC(=C(C=C1COC(=O)C2=CC(=C(C=C2)O)O)O)O[C@H]...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C[C@@H]1CCC[C@@H](N1CCCC(C2=CC=CC=C2)(C3=CC=CC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\t\n",
    "•\t**smiles_file_path:** Path to your input TSV file containing SMILES strings.\n",
    "\n",
    "•\t**output_dir:** Directory where final results will be stored.\n",
    "\n",
    "•\t**intermediate_files:** Directory where intermediate results will be stored.\n",
    "\n",
    "•\t**final_output_path:** Path to the final JSON file containing classification results.\n",
    "\n",
    "•\t**Loading Data:** Reads the TSV file into a pandas DataFrame and drops any rows with missing values."
   ],
   "id": "e6d9d88734b9fd5f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **4. Canonicalizing SMILES**\n",
    "Canonicalization ensures that each SMILES string has a unique representation."
   ],
   "id": "b2d04b1eca938c16"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:16.526694Z",
     "start_time": "2025-01-11T06:11:16.514755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Canonicalize SMILES\n",
    "smiles_df['Canonical_SMILES'] = smiles_df['SMILES'].apply(\n",
    "    lambda x: MoleCule.from_smiles(x).canonical_smiles if x else None\n",
    ")\n",
    "\n",
    "# Count invalid SMILES after canonicalization\n",
    "invalid_smiles = smiles_df['Canonical_SMILES'].isnull().sum()\n",
    "print(f\"Number of invalid SMILES after canonicalization: {invalid_smiles}\")\n",
    "\n",
    "# Remove invalid entries\n",
    "if invalid_smiles > 0:\n",
    "    smiles_df = smiles_df.dropna(subset=['Canonical_SMILES'])\n",
    "    print(f\"Removed {invalid_smiles} invalid SMILES entries.\")\n",
    "\n",
    "# Reset index after cleaning\n",
    "smiles_df.reset_index(drop=True, inplace=True)"
   ],
   "id": "f2df29bdb19fe39c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of invalid SMILES after canonicalization: 0\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "•\t**Canonicalization:** Uses the MoleCule class to convert each SMILES string to its canonical form.\n",
    "\n",
    "•\t**Invalid Entries:** Counts and removes any SMILES strings that couldn’t be canonized.\n",
    "\n",
    "•\t**Cleaning:** Ensures that only valid and unique SMILES strings are retained for further processing."
   ],
   "id": "968910ce5862ed91"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **5. Generating SMILES Mapping**\n",
    "\n",
    "Creating a mapping from original to canonical SMILES helps in tracking and verifying the classification results."
   ],
   "id": "349512ba9e5f3e26"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:17.021953Z",
     "start_time": "2025-01-11T06:11:17.016995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyclassyfire.src.utils import save_smiles_mapping\n",
    "\n",
    "# Extract the list of canonical SMILES\n",
    "canonical_smiles_list = smiles_df['Canonical_SMILES'].tolist()\n",
    "canonical_smiles_list = list(set(canonical_smiles_list))\n",
    "\n",
    "# Extract the list of original SMILES\n",
    "original_smiles_list = smiles_df['SMILES'].tolist()\n",
    "original_smiles_list = list(set(original_smiles_list))\n",
    "\n",
    "# Save the mapping from original to canonical SMILES\n",
    "save_smiles_mapping(original_smiles_list, output_dir)"
   ],
   "id": "8fdb765e70db59c5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully saved SMILES mapping to ../sample_data/output/mapping.json.\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "•\t**Deduplication:** Removes duplicate SMILES strings to optimize processing.\n",
    "\n",
    "•\t**Mapping:** Uses the save_smiles_mapping function to create and save a JSON file that maps each original SMILES to its canonical form."
   ],
   "id": "efee8896ea2e500c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **6. Processing Batches for Classification**\n",
    "\n",
    "Classification is performed in batches to efficiently handle large datasets and manage API interactions."
   ],
   "id": "2463ca7147073e73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:17.638249Z",
     "start_time": "2025-01-11T06:11:17.575965Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyclassyfire.src.batch import process_batches_with_saving_and_retry\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 100          # Number of SMILES per job\n",
    "max_retries = 1           # Maximum number of retries for failed batches\n",
    "retry_delay = 10         # Delay between retries in seconds\n",
    "\n",
    "# Process the batches with resumption and retry logic\n",
    "intermediate_files = process_batches_with_saving_and_retry(\n",
    "    smiles_list=canonical_smiles_list,\n",
    "    batch_size=batch_size,\n",
    "    output_dir=intermediate_files_path,\n",
    "    max_retries=max_retries,\n",
    "    retry_delay=retry_delay\n",
    ")"
   ],
   "id": "5fdb6bbec5331642",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-11 07:11:17,634 - INFO - All SMILES: 10\n",
      "2025-01-11 07:11:17,635 - INFO - Loaded results from ../sample_data/output/intermediate_files/intermediate_1.json\n",
      "2025-01-11 07:11:17,636 - INFO - Already processed SMILES: 10\n",
      "2025-01-11 07:11:17,636 - INFO - Remaining SMILES to process: 0\n",
      "2025-01-11 07:11:17,636 - INFO - Remaining unique SMILES to process after removing duplicates: 0\n",
      "2025-01-11 07:11:17,637 - INFO - Total remaining batches to process: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SMILES: 10\n",
      "Already processed SMILES: 10\n",
      "Remaining SMILES to process: 0\n",
      "Remaining unique SMILES to process after removing duplicates: 0\n",
      "Total remaining batches to process: 0\n",
      "All batches have already been processed.\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "\n",
    "•\t**Batch Size:** Determines how many SMILES strings are processed in each API call.\n",
    "\n",
    "•\t**Retry Logic:** If a batch fails, the function will retry processing it up to max_retries times with a delay of retry_delay seconds between attempts.\n",
    "\n",
    "•\t**Function:** process_batches_with_saving_and_retry handles the classification process, saves intermediate results, and manages resuming process from last batch.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "•\t**Multiple Runs**: If some batches fail despite retries, consider running the process_batches_with_saving_and_retry function multiple times to ensure all SMILES strings are classified."
   ],
   "id": "669a9fdbe68293"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **7. Merging Intermediate Results**\n",
    "\n",
    "After processing all batches, the intermediate JSON files need to be merged into a single result file."
   ],
   "id": "bc606ae33fef0625"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:18.354412Z",
     "start_time": "2025-01-11T06:11:18.349786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyclassyfire.src.utils import merge_intermediate_files\n",
    "\n",
    "# Merge the intermediate files into the final JSON\n",
    "merge_intermediate_files(intermediate_files_path, final_output_path)"
   ],
   "id": "cc780b9382f8618d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully merged 1 files into ../sample_data/output/output.json.\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "•\t**Function:** merge_intermediate_files consolidates all intermediate JSON files into a single output.json ",
   "id": "48f997ca8cffd4cf"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## **8. Evaluating Classification Results**\n",
    "\n",
    "Once classification is complete, it’s essential to evaluate the results."
   ],
   "id": "b21e5aaee6460fc3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-11T06:11:19.732441Z",
     "start_time": "2025-01-11T06:11:19.728011Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pyclassyfire.src.utils import check_all_smiles_present\n",
    "\n",
    "# Check if all SMILES are present in the final output\n",
    "missing_smiles_mapping = check_all_smiles_present(final_output_path, canonical_smiles_list)\n",
    "\n",
    "# Display summary of missing SMILES\n",
    "if missing_smiles_mapping:\n",
    "    print(f\"Number of missing SMILES: {len(missing_smiles_mapping)}\")\n",
    "    print(\"Check 'missing_smiles.json' for details.\")\n",
    "else:\n",
    "    print(\"All SMILES have been successfully processed.\")"
   ],
   "id": "93739fb9b5cae4a9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All SMILES are present in the final output.\n",
      "All SMILES have been successfully processed.\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "•\t**Function:** check_all_smiles_present verifies that every canonical SMILES string has a corresponding entry in the final classification results.\n",
    "\n",
    "•\t**Missing SMILES:** If any SMILES strings are missing, they are detailed in a missing_smiles.json file for further investigation.\n",
    "\n",
    "**Hint:**\n",
    "\n",
    "•\tInvestigate Missing SMILES: If missing_smiles.json is generated, review it to understand which SMILES strings weren’t classified and why. This can help in troubleshooting and ensuring complete data processing."
   ],
   "id": "e243d05b442dce90"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "c7975a504b0bde0f",
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "source": "",
   "id": "1258ae2af314c20d",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
